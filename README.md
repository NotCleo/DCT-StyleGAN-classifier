# DCT-StyleGAN-classifier

This project aims to detect deepfake images generated by StyleGAN models by analyzing their frequency domain characteristics. It uses the Discrete Cosine Transform (DCT) to extract spectral features from images, which are then fed into a CNN for binary classification (real vs. fake). The project is inspired by frequency analysis techniques for deepfake detection and builds on the idea that synthetic images, such as those generated by StyleGAN, exhibit distinct artifacts in the frequency domain compared to real images.

The model is trained on a dataset of real and StyleGAN-generated facial images, with preprocessing steps including face detection using MTCNN and DCT computation for feature extraction.
Features

    Frequency Analysis with DCT: Extracts spectral features from images to capture deepfake artifacts.
    Face Detection with MTCNN: Automatically detects and crops faces from input images.
    CNN Classifier: A lightweight CNN model to classify images as real or fake based on DCT features.
    Pre-trained Model: Includes a pre-trained .h5 model for inference.
    Inference Script: Provides a script to test new images for deepfake detection.

Requirements

    Python 3.8+
    Libraries:
        opencv-python (for image processing)
        numpy (for numerical operations)
        tensorflow (for the CNN model)
        mtcnn (for face detection)
        scikit-learn (for train-test splitting)

Dataset trained on 

    https://www.kaggle.com/datasets/kshitizbhargava/deepfake-face-images/data 
    https://www.kaggle.com/datasets/arnaud58/flickrfaceshq-dataset-ffhq/data
